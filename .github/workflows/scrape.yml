name: Daily Scrape (safe)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "22 2 * * *"   # run daily 02:22 UTC

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Show repo layout (debug)
        shell: bash
        run: |
          echo "Branch: $GITHUB_REF"
          echo "Repo root contents:"
          ls -la
          echo "Workflows:"
          ls -la .github/workflows || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (resilient)
        shell: bash
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: "1"
          PIP_NO_INPUT: "1"
        run: |
          set -e
          python -V
          python -m pip install --upgrade pip setuptools wheel
          if [ -f requirements.txt ]; then
            pip install --only-binary=:all: -r requirements.txt || pip install -r requirements.txt
          fi
          # optional cloud bypass lib
          pip install --only-binary=:all: cloudscraper==1.2.71 || true
          pip list

      - name: Run scraper (tolerant)
        shell: bash
        run: |
          set -e
          mkdir -p out
          if [ -f scrape.py ]; then
            echo "Running scrape.pyâ€¦"
            python scrape.py || echo "::warning ::scraper failed, continuing to write empty CSVs"
          else
            echo "::warning ::scrape.py not found, writing empty CSVs"
          fi

          # Always produce CSVs so later steps don't fail
          if [ ! -f out/current_snapshot.csv ]; then
            echo "timestamp_iso,site_name,product_name,sku,product_url,status,price_value,currency,raw_price_text,source_url,notes" > out/current_snapshot.csv
          fi
          if [ ! -f out/products_history.csv ]; then
            cp out/current_snapshot.csv out/products_history.csv
          fi

          echo "Out dir contents:"
          ls -la out || true

      - name: Commit & push results (if changed)
        shell: bash
        run: |
          git add out/*.csv 2>/dev/null || true
          if ! git diff --cached --quiet; then
            git config user.name "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git commit -m "Update scraped data [skip ci]"
            git push
            echo "Changes pushed."
          else
            echo "No changes to commit."
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scrape-outputs
          path: out/*
          if-no-files-found: warn

      - name: Trigger Make Webhook (JSON)
         env:
    MAKE_WEBHOOK_URL: "https://hook.us2.make.com/v8xg1sfegycppt03qbkodgx9eesaabl6"
  run: |
    curl -fsS -X POST \
      -H "Content-Type: application/json" \
      -d "{\"source\":\"github\",\"repo\":\"${{ github.repository }}\",\"run_id\":\"${{ github.run_id }}\",\"sha\":\"${{ github.sha }}\",\"ts\":\"${{ github.run_number }}\"}" \
      "$MAKE_WEBHOOK_URL"


